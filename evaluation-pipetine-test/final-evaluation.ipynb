{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import openai\n",
    "from openai import APIError\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import AutoModel\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoModel\n",
    "from collections import defaultdict\n",
    "# import pytrec_eval\n",
    "import json\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "import CustomInformationRetrievalEvaluator\n",
    "import importlib\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# must for Custom scripts\n",
    "importlib.reload(CustomInformationRetrievalEvaluator)\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jobs(data_pair, filename, model = \"text-embedding-3-small\"):    \n",
    "    jobs = [\n",
    "                {\n",
    "                    \"model\": model,\n",
    "                    # \"response_format\": \"json\", # TODO check \n",
    "                    # \"temperature\": 0,\n",
    "                    \"metadata\": {\"id\": indx},\n",
    "                    \"input\": text\n",
    "                }\n",
    "                for indx, text in data_pair.items()\n",
    "            ]\n",
    "    with open(filename, \"w\") as f:\n",
    "        for job in jobs:\n",
    "            json_string = json.dumps(job)\n",
    "            f.write(json_string + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# python evaluation-pipetine-test/api_request_parallel_processor.py   --requests_filepath evaluation-pipetine-test/datasets/queries   --save_filepath evaluation-pipetine-test/datasets/text-embedding-3-small-squad-queries.jsonl   --request_url https://api.openai.com/v1/embeddings   --max_requests_per_minute 1500   --max_tokens_per_minute 6250000   --token_encoding_name cl100k_base   --max_attempts 5   --logging_level 20 \n",
    "# python evaluation-pipetine-test/api_request_parallel_processor.py   --requests_filepath evaluation-pipetine-test/datasets/context   --save_filepath evaluation-pipetine-test/datasets/text-embedding-3-small-squad-corpus.jsonl   --request_url https://api.openai.com/v1/embeddings   --max_requests_per_minute 1500   --max_tokens_per_minute 6250000   --token_encoding_name cl100k_base   --max_attempts 5   --logging_level 20 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_embedding_dict(file_path):\n",
    "#     returned_dict = {}\n",
    "#     # Open and iterate through the .jsonl file\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             data = json.loads(line)  # Load the JSON object from the line\n",
    "#             # Process the data as needed\n",
    "#             indx = data[-1]['id']\n",
    "#             embedding = data[1]['data'][0]['embedding']\n",
    "#             returned_dict[indx] = embedding\n",
    "#     return returned_dict\n",
    "\n",
    "# dict_emb = make_embedding_dict(\"processed_datasets/example_requests_to_parallel_process_results.jsonl\")\n",
    "# print(dict_emb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_datasets/squad_processed.parquet\n",
      "text-embedding-3-small-squad\n",
      "True\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/text-embedding-3-small-squad-queries.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(models_[model_name])\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_openAI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[41], line 52\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model_name, dataset_name, is_openAI)\u001b[0m\n\u001b[0;32m     42\u001b[0m ir_evaluator \u001b[38;5;241m=\u001b[39m CustomInformationRetrievalEvaluator\u001b[38;5;241m.\u001b[39mInformationRetrievalEvaluator(\n\u001b[0;32m     43\u001b[0m queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m     44\u001b[0m corpus\u001b[38;5;241m=\u001b[39mcorpus,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m write_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m model_name, model \u001b[38;5;241m=\u001b[39m get_model_or_model_name(model_name, is_openAI)\n\u001b[1;32m---> 52\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mir_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenAI_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# print(ir_evaluator.primary_metric)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# print(results[ir_evaluator.primary_metric])\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32md:\\smartCat\\SRBedding\\evaluation-pipetine-test\\CustomInformationRetrievalEvaluator.py:229\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.__call__\u001b[1;34m(self, model, output_path, openAI_model, epoch, steps, *args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     out_txt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (truncated to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation Retrieval Evaluation of the model on the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 229\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrices(model, openAI_model\u001b[38;5;241m=\u001b[39mopenAI_model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Write results to disc\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_csv:\n",
      "File \u001b[1;32md:\\smartCat\\SRBedding\\evaluation-pipetine-test\\CustomInformationRetrievalEvaluator.py:344\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.compute_metrices\u001b[1;34m(self, model, corpus_model, corpus_embeddings, openAI_model)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# Compute embedding for the queries\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Dodato\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m openAI_model:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# query_embeddings = [self.get_embedding(x, model=openAI_model) for x in self.queries]\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mopenAI_model\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-queries.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m nullcontext() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtruncate_sentence_embeddings(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim):\n",
      "File \u001b[1;32md:\\smartCat\\SRBedding\\evaluation-pipetine-test\\CustomInformationRetrievalEvaluator.py:321\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.get_embeddings_from_file\u001b[1;34m(self, file_path, keys)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings_from_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path, keys):\n\u001b[0;32m    320\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 321\u001b[0m     embedding_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_embedding_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[0;32m    323\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(embedding_dict[key])\n",
      "File \u001b[1;32md:\\smartCat\\SRBedding\\evaluation-pipetine-test\\CustomInformationRetrievalEvaluator.py:310\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator._make_embedding_dict\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m    308\u001b[0m returned_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# Open and iterate through the .jsonl file\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m    312\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)  \u001b[38;5;66;03m# Load the JSON object from the line\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/text-embedding-3-small-squad-queries.jsonl'"
     ]
    }
   ],
   "source": [
    "def get_data_for_evaluation(dataset_name):\n",
    "    loaded_table = pq.read_table(dataset_name)\n",
    "    df = loaded_table.to_pandas()\n",
    "    corpus = {}\n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    query_idx = 1\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx >= 100:  # Break the loop after two iterations\n",
    "            break\n",
    "        corpus[idx] = row['context']\n",
    "        for query in row['queries']:\n",
    "            query = query.strip()\n",
    "            queries[query_idx] = query\n",
    "            if query_idx not in relevant_docs:\n",
    "                relevant_docs[query_idx] = set()\n",
    "            relevant_docs[query_idx].add(idx)\n",
    "            query_idx += 1\n",
    "    save_jobs(queries, \"datasets/queries\")\n",
    "    save_jobs(queries, \"datasets/contexts\")\n",
    "    return queries, corpus, relevant_docs\n",
    "\n",
    "def load_sentence_tranformer_from_transformer(model_name):\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    # Combine the model and pooling into a SentenceTransformer\n",
    "    word_embedding_model = models.Transformer(model_name_or_path=model_name)\n",
    "    pooling_model = models.Pooling(word_embedding_dimension=model.config.hidden_size, pooling_mode_mean_tokens=True)\n",
    "    return SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "def get_model_or_model_name(model_name, is_openAI):\n",
    "    model = None\n",
    "    if not is_openAI:\n",
    "        model = load_sentence_tranformer_from_transformer(model_name)\n",
    "        model_name = None\n",
    "    return model_name,model\n",
    "\n",
    "def evaluate(model_name, dataset_name, is_openAI):\n",
    "\n",
    "    name = f\"{model_name}-{dataset_name}-evlatuation\"\n",
    "    queries, corpus, relevant_docs = get_data_for_evaluation(dataset_name)\n",
    "\n",
    "    ir_evaluator = CustomInformationRetrievalEvaluator.InformationRetrievalEvaluator(\n",
    "    queries=queries,\n",
    "    corpus=corpus,\n",
    "    relevant_docs=relevant_docs,\n",
    "    name=name,\n",
    "    write_csv=True\n",
    "    )\n",
    "\n",
    "    model_name, model = get_model_or_model_name(model_name, is_openAI)\n",
    "        \n",
    "    results = ir_evaluator(model, openAI_model=model_name)\n",
    "    # print(ir_evaluator.primary_metric)\n",
    "    # print(results[ir_evaluator.primary_metric])\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datasets = [\"processed_datasets/squad_processed.parquet\"]\n",
    "\n",
    "models_ = {\n",
    "#  \"google-bert/bert-base-multilingual-cased\": False\n",
    " \"text-embedding-3-small-squad\" : True   \n",
    "}\n",
    "\n",
    "for dataset_name, model_name in zip(datasets, models_.keys()):\n",
    "    print(dataset_name)\n",
    "    print(model_name)\n",
    "    print(models_[model_name])\n",
    "    print(evaluate(model_name=model_name, dataset_name=dataset_name, is_openAI=models_[model_name]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@1': 0.8620689655172413,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@10': 1.0,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@3': 1.0,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@5': 1.0,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_map@100': np.float64(0.925287356321839),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_mrr@10': 0.9252873563218391,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_ndcg@10': np.float64(0.9445789400246336),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@1': np.float64(0.8620689655172413),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@10': np.float64(0.10000000000000003),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@3': np.float64(0.3333333333333334),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@5': np.float64(0.20000000000000007),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@1': np.float64(0.8620689655172413),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@10': np.float64(1.0),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@3': np.float64(1.0),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@5': np.float64(1.0),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@1': 0.8620689655172413,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@10': 1.0,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@3': 1.0,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@5': 1.0,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_map@100': np.float64(0.925287356321839),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_mrr@10': 0.9252873563218391,\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_ndcg@10': np.float64(0.9445789400246336),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@1': np.float64(0.8620689655172413),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@10': np.float64(0.10000000000000003),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@3': np.float64(0.3333333333333334),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@5': np.float64(0.20000000000000007),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@1': np.float64(0.8620689655172413),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@10': np.float64(1.0),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@3': np.float64(1.0),\n",
      " 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@5': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "pprint({'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@1': 0.8620689655172413, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@3': 1.0, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@5': 1.0, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_accuracy@10': 1.0, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@1': np.float64(0.8620689655172413), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@3': np.float64(0.3333333333333334), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@5': np.float64(0.20000000000000007), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_precision@10': np.float64(0.10000000000000003), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@1': np.float64(0.8620689655172413), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@3': np.float64(1.0), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@5': np.float64(1.0), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_recall@10': np.float64(1.0), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_ndcg@10': np.float64(0.9445789400246336), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_mrr@10': 0.9252873563218391, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_cosine_map@100': np.float64(0.925287356321839), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@1': 0.8620689655172413, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@3': 1.0, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@5': 1.0, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_accuracy@10': 1.0, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@1': np.float64(0.8620689655172413), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@3': np.float64(0.3333333333333334), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@5': np.float64(0.20000000000000007), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_precision@10': np.float64(0.10000000000000003), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@1': np.float64(0.8620689655172413), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@3': np.float64(1.0), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@5': np.float64(1.0), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_recall@10': np.float64(1.0), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_ndcg@10': np.float64(0.9445789400246336), 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_mrr@10': 0.9252873563218391, 'text-embedding-3-small-datasets/dataset_processed.parquet-evlatuation_dot_map@100': np.float64(0.925287356321839)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
