{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\smartCat\\SRBedding\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pyarrow.parquet as pq\n",
    "import pandas\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from sentence_transformers import SentenceTransformer,  models, util\n",
    "from sentence_transformers.readers import InputExample\n",
    "from enum import Enum\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime\n",
    "import math\n",
    "import sentence_transformers.losses  as losses\n",
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import tqdm\n",
    "from sentence_transformers.cross_encoder import CrossEncoder  \n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Set up basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class QueryType(Enum):\n",
    "    SHORT = 'short_query'\n",
    "    MEDIUM = 'medium_query'\n",
    "    LONG = 'long_query'\n",
    "\n",
    "\n",
    "def load_df(file: Path) -> pandas.DataFrame:\n",
    "    loaded_table = pq.read_table(file)\n",
    "    return loaded_table.to_pandas()\n",
    "\n",
    "\n",
    "def convert_dataset(dataframe: pandas.DataFrame, question_type: str) -> List[InputExample]:\n",
    "    dataset_samples = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        score = float(row['scores'][question_type])/5.0\n",
    "        sample = InputExample(texts=[row['context'], row[question_type]],\n",
    "                                 label=score)\n",
    "        dataset_samples.append(sample)\n",
    "    return dataset_samples\n",
    "\n",
    "def convert_to_hf_dataset(input_examples: List[InputExample]) -> Dataset:\n",
    "    # Convert each InputExample into a dictionary\n",
    "    data_dict = {\n",
    "        \"sentence1\": [ex.texts[0] for ex in input_examples],\n",
    "        \"sentence2\": [ex.texts[1] for ex in input_examples],\n",
    "        \"score\": [ex.label for ex in input_examples]\n",
    "    }\n",
    "    \n",
    "    # Create a Hugging Face Dataset\n",
    "    return Dataset.from_dict(data_dict)\n",
    "\n",
    "def get_train_and_eval_datasets(dataset_name: Path) -> Tuple[Dataset, Dataset, Dataset, List]:\n",
    "    # NOTE francuzi su 70:15:15 ovde je 80:10:10\n",
    "    df = load_df(file=dataset_name)\n",
    "    training_samples = convert_dataset(df, QueryType.LONG.value)\n",
    "\n",
    "    random.shuffle(training_samples)\n",
    "\n",
    "    # Manually split the dataset while retaining the original structure\n",
    "    dataset_size = len(training_samples)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    dev_size = int(0.1 * dataset_size)\n",
    "\n",
    "    train_samples = training_samples[:train_size]\n",
    "    dev_samples = training_samples[train_size:train_size + dev_size]\n",
    "    eval_samples = training_samples[train_size + dev_size:]\n",
    "\n",
    "    # Convert lists to Hugging Face Datasets\n",
    "    train_dataset = convert_to_hf_dataset(train_samples)\n",
    "    dev_dataset = convert_to_hf_dataset(dev_samples)\n",
    "    eval_dataset = convert_to_hf_dataset(eval_samples)\n",
    "\n",
    "    return train_dataset, dev_dataset, eval_dataset, eval_samples\n",
    "\n",
    "def make_sentence_transformer(model_name: str, max_seq_length: int = 512) -> SentenceTransformer:\n",
    "    word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "    # Apply mean pooling to get one fixed sized sentence vector\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                                pooling_mode_cls_token=False,\n",
    "                                pooling_mode_max_tokens=False,\n",
    "                                pooling_mode_mean_tokens=True)\n",
    "    return SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "def train_a_model(model_name:str, args: SentenceTransformerTrainingArguments, train_dataset, eval_dataset):\n",
    "    sentence_transformer = make_sentence_transformer(model_name)\n",
    "    train_loss = losses.CosineSimilarityLoss(model=sentence_transformer)\n",
    "    train_loss = losses.MatryoshkaLoss(sentence_transformer, train_loss, [768, 512, 256, 128, 64])\n",
    "\n",
    "    # # 6. (Optional) Create an evaluator & evaluate the base model\n",
    "    dev_evaluator = make_evaluator(eval_dataset, sentence_transformer)\n",
    "\n",
    "    # 7. Create a trainer & train\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=sentence_transformer,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        loss=train_loss,\n",
    "        evaluator=dev_evaluator,\n",
    "        \n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # # (Optional) Evaluate the trained model on the test set\n",
    "    test_evaluator = make_evaluator(eval_dataset, sentence_transformer)\n",
    "\n",
    "    # 8. Save the trained model\n",
    "    # TODO da li ovako cuvati\n",
    "    sentence_transformer.save_pretrained(\"output/mpnet-base-all-nli-triplet/final\")\n",
    "\n",
    "    # 9. (Optional) Push it to the Hugging Face Hub\n",
    "    # model.push_to_hub(\"mpnet-base-all-nli-triplet\")\n",
    "\n",
    "def make_evaluator(dataset, sentence_transformer):\n",
    "    dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "        sentences1=dataset['sentence1'],\n",
    "        sentences2=dataset['sentence2'],\n",
    "        scores=dataset['score'],\n",
    "        main_similarity=SimilarityFunction.COSINE,\n",
    "        name=\"sts-dev\",\n",
    "        write_csv=True\n",
    "    )\n",
    "\n",
    "    dev_evaluator(model=sentence_transformer)\n",
    "    return dev_evaluator\n",
    "\n",
    "\n",
    "def make_gold_samle(df_train, batch_size):\n",
    "    gold_samples = []\n",
    "    batch_size = batch_size\n",
    "    for df in df_train:\n",
    "        score = float(df['score'])  # Already normalized scores to range 0 ... 1\n",
    "        gold_samples.append(InputExample(texts=[df['sentence1'], df['sentence2']], label=score))\n",
    "        gold_samples.append(InputExample(texts=[df['sentence2'], df['sentence1']], label=score))\n",
    "    # We wrap gold_samples (which is a List[InputExample]) into a pytorch DataLoader\n",
    "    print(df_train)\n",
    "    print(\"AAAAAAAAAAAAAAAAAAAAAAAAA\")\n",
    "    print(gold_samples)\n",
    "    print(gold_samples['texts'])\n",
    "    return DataLoader(gold_samples, shuffle=True, batch_size=batch_size), gold_samples\n",
    "\n",
    "def get_silver_datset(gold_samples):\n",
    "\n",
    "    # Generation of the sentences\n",
    "    sentences = set()\n",
    "\n",
    "    for sample in gold_samples:\n",
    "        sentences.update(sample.texts)\n",
    "\n",
    "    sentences = list(sentences) # unique sentences\n",
    "    sent2idx = {sentence: idx for idx, sentence in enumerate(sentences)} # storing id and sentence in dictionary\n",
    "    duplicates = set((sent2idx[data.texts[0]], sent2idx[data.texts[1]]) for data in gold_samples) # not to include gold pairs of sentences again\n",
    "    return sentences, sent2idx, duplicates\n",
    "\n",
    "\n",
    "def load_model(model_save_path: str) -> SentenceTransformer:\n",
    "    \"\"\"\n",
    "    Load a SentenceTransformer model from a specified path.\n",
    "\n",
    "    :param model_save_path: The directory where the model is saved.\n",
    "    :return: The loaded SentenceTransformer model.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_save_path)\n",
    "    return model\n",
    "\n",
    "def make_combined_data(batch_size, gold_samples, silver_data, silver_scores):\n",
    "    silver_samples = list(InputExample(texts=[data[0], data[1]], label=score) for \\\n",
    "        data, score in zip(silver_data, silver_scores))\n",
    "    train_dataloader = DataLoader(gold_samples + silver_samples, shuffle=True, batch_size=batch_size)\n",
    "    return train_dataloader\n",
    "\n",
    "def train_bi_encoder_on_silver(num_epochs, batch_size, model_save_path, gold_samples):\n",
    "    sentences, sent2idx, duplicates = get_silver_datset(gold_samples=gold_samples)\n",
    "    semantic_search_model = load_model(model_save_path=f'{model_save_path}/checkpoint-{num_epochs}/')\n",
    "    embeddings = semantic_search_model.encode(sentences, batch_size=batch_size, convert_to_tensor=True)\n",
    "    top_k=2\n",
    "    silver_data = []\n",
    "    progress = tqdm.tqdm(unit=\"docs\", total=len(sent2idx))\n",
    "    for idx in range(len(sentences)):\n",
    "        sentence_embedding = embeddings[idx]\n",
    "        cos_scores = util.cos_sim(sentence_embedding, embeddings)[0]\n",
    "        cos_scores = cos_scores.cpu()\n",
    "        progress.update(1)\n",
    "\n",
    "        # We use torch.topk to find the highest 5 scores\n",
    "        top_results = torch.topk(cos_scores, k=top_k+1)\n",
    "        \n",
    "        for score, iid in zip(top_results[0], top_results[1]):\n",
    "            if iid != idx and (iid, idx) not in duplicates:\n",
    "                silver_data.append((sentences[idx], sentences[iid]))\n",
    "                duplicates.add((idx,iid))            \n",
    "    progress.reset()\n",
    "    progress.close()\n",
    "    return semantic_search_model,silver_data\n",
    "\n",
    "def train_cross_encoder(num_epochs, batch_size, model_name, train_dataset, eval_with_text, cross_encoder_path):\n",
    "    cross_encoder = CrossEncoder(model_name, num_labels=1)\n",
    "\n",
    "    evaluator = CECorrelationEvaluator.from_input_examples(eval_with_text, name='sts-dev')\n",
    "    train_dataloader, gold_samples = make_gold_samle(train_dataset, batch_size)\n",
    "    # Configure the training\n",
    "    warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "\n",
    "    cross_encoder.fit(train_dataloader=train_dataloader,\n",
    "            evaluator=evaluator,\n",
    "            epochs=num_epochs,\n",
    "            evaluation_steps=1000,\n",
    "            optimizer_params={'lr': 1e-5, \n",
    "                                'eps': 1e-6,},\n",
    "            warmup_steps=warmup_steps,\n",
    "            output_path=cross_encoder_path)\n",
    "            \n",
    "    return gold_samples\n",
    "\n",
    "def train_bi_encoder(num_epochs, batch_size, model_name, train_dataset, eval_dataset, model_save_path):\n",
    "    warmup_steps = math.ceil(len(train_dataset) * num_epochs  * 0.1)\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "            # Required parameter:\n",
    "            output_dir=model_save_path,\n",
    "            # Optional training parameters:\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=2e-5,\n",
    "            warmup_ratio=0.1,\n",
    "            fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "            bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "            # batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "            # Optional tracking/debugging parameters:\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=100,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=100,\n",
    "            save_total_limit=2,\n",
    "            logging_steps=100,\n",
    "            run_name=\"proba\",  # Will be used in W&B if `wandb` is installed\n",
    "            warmup_steps=warmup_steps,\n",
    "        )\n",
    "    train_a_model(model_name, args=args, eval_dataset=eval_dataset, train_dataset=train_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "d:\\smartCat\\SRBedding\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset:\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Cosine-Similarity :\tPearson: 0.9195\tSpearman: 0.9487\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Manhattan-Distance:\tPearson: 0.8428\tSpearman: 0.7379\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Euclidean-Distance:\tPearson: 0.8547\tSpearman: 0.7379\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Dot-Product-Similarity:\tPearson: 0.9107\tSpearman: 0.9487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f68d639c354dc0a3f98ea5317b032c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.trainer:Saving model checkpoint to output\\trained_google-bert-bert-base-multilingual-cased-19-08-2024_17-13-48\\checkpoint-2\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to output\\trained_google-bert-bert-base-multilingual-cased-19-08-2024_17-13-48\\checkpoint-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b74960fd8d944ba9c4220490de1d7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdad39510da4b26b9c15dc904dc76fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:EmbeddingSimilarityEvaluator: Evaluating the model on the sts-dev dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 288.5244, 'train_samples_per_second': 0.097, 'train_steps_per_second': 0.007, 'train_loss': 0.20177501440048218, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Cosine-Similarity :\tPearson: 0.9176\tSpearman: 0.9487\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Manhattan-Distance:\tPearson: 0.8564\tSpearman: 0.7379\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Euclidean-Distance:\tPearson: 0.8627\tSpearman: 0.7379\n",
      "INFO:sentence_transformers.evaluation.EmbeddingSimilarityEvaluator:Dot-Product-Similarity:\tPearson: 0.9136\tSpearman: 0.9487\n",
      "INFO:sentence_transformers.SentenceTransformer:Save model to output/mpnet-base-all-nli-triplet/final\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab002593444443dcbe0e961bcbdfc3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73848737427141efa93c8deb759ec25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 16\n",
    "model_name = \"google-bert/bert-base-multilingual-cased\"\n",
    "dataset_name = Path(\"datasets/train.parquet\")\n",
    "train_dataset, dev_dataset, eval_dataset, eval_with_text = get_train_and_eval_datasets(dataset_name)\n",
    "model_save_path = Path('output/trained_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))\n",
    "\n",
    "train_bi_encoder(num_epochs, batch_size, model_name, train_dataset, eval_dataset, model_save_path)\n",
    "\n",
    "# cross_encoder_path = 'output/cross-encoder/stsb_indomain_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "# gold_samples = train_cross_encoder(num_epochs, batch_size, model_name, train_dataset, eval_with_text, cross_encoder_path)\n",
    "\n",
    "# semantic_search_model, silver_data = train_bi_encoder_on_silver(num_epochs, batch_size, model_save_path, gold_samples)\n",
    "\n",
    "# cross_encoder = CrossEncoder(cross_encoder_path)\n",
    "# silver_scores = cross_encoder.predict(silver_data)\n",
    "# # All model predictions should be between [0,1]\n",
    "# assert all(0.0 <= score <= 1.0 for score in silver_scores)\n",
    "\n",
    "# train_dataloader = make_combined_data(batch_size, gold_samples, silver_data, silver_scores)\n",
    "\n",
    "# train_loss = losses.CosineSimilarityLoss(model=semantic_search_model)\n",
    "# train_loss = losses.MatryoshkaLoss(model=semantic_search_model, loss=train_loss, matryoshka_dims=[768, 512, 256, 128, 64])\n",
    "\n",
    "# evaluator = make_evaluator(dataset=dev_dataset, sentence_transformer=semantic_search_model)\n",
    "\n",
    "# # Configure the training.\n",
    "# warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "\n",
    "# args = SentenceTransformerTrainingArguments(\n",
    "#         # Required parameter:\n",
    "#         output_dir=model_save_path,\n",
    "#         # Optional training parameters:\n",
    "#         num_train_epochs=num_epochs,\n",
    "#         per_device_train_batch_size=batch_size,\n",
    "#         per_device_eval_batch_size=batch_size,\n",
    "#         learning_rate=2e-5,\n",
    "#         warmup_ratio=0.1,\n",
    "#         fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "#         bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "#         # batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "#         # Optional tracking/debugging parameters:\n",
    "#         eval_strategy=\"steps\",\n",
    "#         eval_steps=100,\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps=100,\n",
    "#         save_total_limit=2,\n",
    "#         logging_steps=100,\n",
    "#         run_name=\"proba\",  # Will be used in W&B if `wandb` is installed\n",
    "#         warmup_steps=warmup_steps,\n",
    "#     )\n",
    "\n",
    "# trainer = SentenceTransformerTrainer(\n",
    "#         model=semantic_search_model,\n",
    "#         args=args,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=eval_dataset,\n",
    "#         loss=train_loss,\n",
    "#         evaluator=evaluator,\n",
    "#     )\n",
    "# trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder_path = 'output/cross-encoder/stsb_indomain_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "gold_samples = train_cross_encoder(num_epochs, batch_size, model_name, train_dataset, eval_with_text, cross_encoder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6, 0.6, 1.0, 0.8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "56\n",
      "Kako se osećao autor kada je video čoveka pred vratima od košare koje je zaključao?\n",
      " Kao da je nečastivi bio u meni tako se pomamim, kad vidim čoveka pred vratima od košare, koja su bila otvorena — a ja sam ih mojom rukom zaključao na bravu, pre nego što sam ušao večerati\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "gold_samples = []\n",
    "batch_size = batch_size\n",
    "for df in train_dataset:\n",
    "    score = float(df['score'])  # Already normalized scores to range 0 ... 1\n",
    "    gold_samples.append(InputExample(texts=[df['sentence1'], df['sentence2']], label=score))\n",
    "    gold_samples.append(InputExample(texts=[df['sentence2'], df['sentence1']], label=score))\n",
    "# We wrap gold_samples (which is a List[InputExample]) into a pytorch DataLoader\n",
    "# print(df_train)\n",
    "print(\"AAAAAAAAAAAAAAAAAAAAAAAAA\")\n",
    "print(len(gold_samples))\n",
    "lala = gold_samples[7].texts\n",
    "print(lala[0])\n",
    "print(lala[1])\n",
    "print(gold_samples[5].label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srbedding-4dwWae5r-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
