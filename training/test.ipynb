{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selena/sele/SRBedding/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/selena/sele/SRBedding/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4002 > 256). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-9.32899117e-03, -1.22720767e-02, -3.14273499e-02, -4.82845725e-03,\n",
       "       -6.23348430e-02, -1.07972575e-02,  3.52494046e-02, -8.98217186e-02,\n",
       "       -4.63590352e-03,  4.15462554e-02,  1.13985846e-02, -2.14111693e-02,\n",
       "        1.21306702e-02,  2.75224214e-03, -9.60910507e-03, -5.27121983e-02,\n",
       "       -3.34623642e-02,  1.11243417e-02, -1.36733949e-02, -3.50801311e-02,\n",
       "        5.92552722e-02,  4.08337153e-02,  5.48437284e-03, -3.12680788e-02,\n",
       "       -4.69684303e-02,  5.78201190e-03, -6.62415624e-02, -2.45135054e-02,\n",
       "       -6.36817664e-02, -9.37091932e-02, -2.87860725e-02, -3.41395242e-03,\n",
       "       -1.12735329e-03,  2.36434992e-02,  4.22615139e-03,  2.41409075e-02,\n",
       "        2.37088799e-02,  3.18711735e-02,  6.63504153e-02,  4.81117293e-02,\n",
       "        2.10567154e-02, -4.39121015e-02,  4.11135182e-02,  2.07978804e-02,\n",
       "        1.60469487e-02,  5.94525337e-02, -3.58099826e-02, -2.99333092e-02,\n",
       "       -8.42209756e-02, -9.25723910e-02, -4.40168679e-02,  2.30854806e-02,\n",
       "        2.80580223e-02, -7.66256303e-02, -9.86166373e-02, -8.77759233e-02,\n",
       "        5.31464294e-02,  1.11329639e-02,  3.32085020e-03,  2.42672190e-02,\n",
       "       -1.45263178e-02,  6.37181196e-03,  6.29325733e-02,  6.25975654e-02,\n",
       "       -2.20232029e-02,  4.43222113e-02, -8.71997029e-02, -1.84923653e-02,\n",
       "        2.74285348e-03,  3.92088071e-02, -8.15402716e-02, -5.37983188e-03,\n",
       "        8.98953527e-02,  1.38570100e-01,  4.77230437e-02,  2.06548031e-02,\n",
       "       -1.00544363e-03, -6.40347004e-02, -4.44345362e-02,  8.66880920e-03,\n",
       "       -1.02826819e-01, -1.85473505e-02, -9.52036411e-04, -6.40467554e-02,\n",
       "        1.78392883e-02,  1.46856420e-02,  3.93831953e-02,  4.06830236e-02,\n",
       "       -7.69424811e-02, -5.69039509e-02,  4.30883914e-02,  4.24382947e-02,\n",
       "       -7.74614662e-02, -4.87136608e-03,  8.97897854e-02, -4.29129712e-02,\n",
       "       -4.28894460e-02,  1.18472874e-02, -6.48329556e-02,  5.11911288e-02,\n",
       "        1.02584273e-01,  5.35560958e-02, -5.57623096e-02, -4.82713953e-02,\n",
       "       -4.45994325e-02, -2.21320968e-02, -3.59207876e-02, -1.24936709e-02,\n",
       "        7.93463141e-02, -1.71692378e-03, -7.66792968e-02, -3.59665193e-02,\n",
       "       -1.74878761e-02, -4.34096828e-02, -2.46996526e-02,  3.45226587e-03,\n",
       "       -3.15611213e-02,  4.57642972e-03,  4.26711999e-02,  6.06028251e-02,\n",
       "       -3.20505686e-02, -8.86832550e-03, -4.01968434e-02, -2.17770715e-03,\n",
       "        4.54562120e-02, -3.35034318e-02, -1.36807710e-01,  3.16388786e-33,\n",
       "       -3.61981466e-02,  6.20850846e-02,  3.95764597e-02,  9.75747332e-02,\n",
       "       -1.07442671e-02, -1.03738233e-02,  3.97444004e-03,  3.67202200e-02,\n",
       "       -7.76812807e-02,  9.05237626e-03, -2.71406341e-02,  9.53297038e-03,\n",
       "       -6.22080266e-02,  3.39861028e-02,  4.76560034e-02,  8.43053013e-02,\n",
       "       -3.29152904e-02, -4.01174985e-02, -5.96258268e-02,  5.26578724e-03,\n",
       "       -3.49422321e-02,  3.25706750e-02,  3.81078199e-02, -2.44626123e-02,\n",
       "       -4.03678901e-02, -3.03528644e-02, -4.90073152e-02, -1.78626087e-02,\n",
       "       -7.02912956e-02,  3.63647826e-02, -1.29671708e-01,  5.60198128e-02,\n",
       "       -7.54520372e-02, -1.63421016e-02, -4.35178950e-02, -8.22474062e-02,\n",
       "        1.80491209e-02,  2.72371210e-02, -5.96458018e-02, -5.07776961e-02,\n",
       "       -6.24052547e-02, -2.94247884e-02, -4.78341430e-02,  2.30234880e-02,\n",
       "        7.14543462e-02,  1.71095785e-02, -1.01835933e-02, -3.12566683e-02,\n",
       "        8.57791156e-02,  2.24279035e-02,  4.79822047e-02, -2.70212367e-02,\n",
       "        6.42716214e-02,  6.61483482e-02, -3.78202759e-02,  7.91797936e-02,\n",
       "        4.58254479e-03,  3.61289829e-02, -1.62767712e-02,  4.69206870e-02,\n",
       "        9.98426322e-03, -1.57798324e-02, -9.09256637e-02,  7.57579654e-02,\n",
       "       -6.00348189e-02, -1.13528660e-02, -1.49327992e-02, -2.70841038e-03,\n",
       "        4.98572811e-02,  3.60535011e-02, -1.10413339e-02,  8.20835703e-04,\n",
       "       -4.20967638e-02,  5.75602539e-02,  8.29804596e-03, -3.55811062e-04,\n",
       "       -1.42216040e-02, -1.15757724e-02, -2.20101960e-02,  5.34101836e-02,\n",
       "        3.95983309e-02, -6.20835871e-02,  3.07737403e-02, -4.01253849e-02,\n",
       "       -1.08344354e-01, -5.58493426e-03, -2.84330845e-02, -5.55908084e-02,\n",
       "       -3.49567495e-02, -5.45409657e-02, -6.19388670e-02,  3.99266668e-02,\n",
       "        7.03386292e-02, -1.60842359e-01,  1.33705616e-01, -9.15714360e-33,\n",
       "       -3.19133028e-02,  1.39005601e-01, -2.37853862e-02,  9.45121795e-02,\n",
       "        3.39523703e-02, -2.52129529e-02,  2.31511910e-02,  2.62573287e-02,\n",
       "       -3.97527516e-02,  2.40665860e-02, -1.22905904e-02, -1.70930494e-02,\n",
       "        4.10481654e-02, -4.26855236e-02, -1.16228554e-02,  5.39088473e-02,\n",
       "        7.35975429e-02,  9.82741266e-03,  2.25414280e-02,  2.27959715e-02,\n",
       "       -1.56275406e-02,  1.04422390e-01,  4.37573791e-02,  5.35787381e-02,\n",
       "       -8.21643174e-02,  4.33245748e-02,  1.30293844e-02,  3.56099172e-03,\n",
       "        1.98399022e-01, -4.94222231e-02, -3.87400873e-02,  3.24435299e-03,\n",
       "        5.05392179e-02, -7.82535039e-03,  1.13088312e-02, -6.55254126e-02,\n",
       "        6.36830693e-03, -2.93856449e-02, -8.54262263e-02,  5.72144240e-02,\n",
       "        3.89064051e-04,  3.62737663e-02,  2.01841015e-02, -4.72544618e-02,\n",
       "        6.59233716e-04, -2.95178574e-02,  1.25583895e-02,  2.52532884e-02,\n",
       "       -7.51732662e-02, -2.95651369e-02, -2.65404582e-03, -7.22099766e-02,\n",
       "       -7.55734146e-02,  1.08142542e-02, -4.54268306e-02,  1.55987451e-02,\n",
       "       -6.66525736e-02, -4.20510694e-02, -1.65125704e-03,  5.74317947e-02,\n",
       "        2.85861176e-02, -1.48129119e-02,  3.13229933e-02,  2.44566109e-02,\n",
       "       -1.12993680e-01, -5.58712929e-02,  1.42638525e-03,  4.44677323e-02,\n",
       "        3.46262418e-02,  2.39043068e-02, -6.95243031e-02, -1.09559624e-03,\n",
       "       -1.49241969e-01, -7.65135363e-02,  1.44238621e-01, -3.73514332e-02,\n",
       "        1.42837828e-03, -3.09567023e-02, -2.11329665e-02, -4.70276102e-02,\n",
       "       -7.04243360e-03, -6.89225420e-02,  2.37809066e-02,  5.90179227e-02,\n",
       "        6.51861131e-02,  8.10193494e-02, -4.39843424e-02,  3.50926667e-02,\n",
       "       -2.70785801e-02,  2.45869327e-02, -1.64263253e-03, -6.08744053e-03,\n",
       "        3.98547463e-02, -7.97722396e-03, -1.36507794e-01, -4.58184957e-08,\n",
       "       -3.22524607e-02, -2.15806235e-02, -4.06408533e-02,  1.55854775e-02,\n",
       "       -4.63013873e-02,  8.04981366e-02,  3.06393411e-02, -6.56615617e-03,\n",
       "       -4.02869135e-02, -4.86442680e-03, -1.04809329e-02,  5.79997599e-02,\n",
       "       -2.96907406e-02,  2.90170182e-02, -3.80469859e-02, -3.89275812e-02,\n",
       "       -3.99267785e-02, -1.61127839e-03,  1.97164752e-02, -9.86570120e-03,\n",
       "       -5.14662191e-02, -7.14014694e-02,  2.75269970e-02,  2.29476728e-02,\n",
       "        1.50835572e-03, -3.94706838e-02, -2.65351981e-02,  2.06951797e-02,\n",
       "        5.59982322e-02, -2.73863282e-02,  2.28221924e-03,  1.06366910e-02,\n",
       "       -6.13784008e-02, -1.88600142e-02, -2.52904072e-02, -2.02920455e-02,\n",
       "        2.91182138e-02, -1.27890557e-02, -2.14676335e-02,  2.74141766e-02,\n",
       "       -1.37466490e-02,  4.09764908e-02, -3.32302712e-02,  6.82150275e-02,\n",
       "       -7.85874128e-02,  4.14061965e-03, -1.22167237e-01, -5.00805900e-02,\n",
       "       -9.65584591e-02, -3.70443352e-02,  4.14775312e-02, -7.19098898e-04,\n",
       "       -8.77487585e-02,  6.02805093e-02, -7.63786677e-03, -3.96388285e-02,\n",
       "       -7.58204563e-03, -1.71881970e-02, -1.28035605e-01, -6.13249429e-02,\n",
       "        5.86133339e-02,  3.13932933e-02,  8.89391527e-02,  3.19771022e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "my_text = \"this is a test \"*1000\n",
    "\n",
    "try:\n",
    "  o = model[0].tokenizer(my_text, return_attention_mask=False, return_token_type_ids=False)\n",
    "  if len(o.input_ids) > model.max_seq_length:\n",
    "    raise ValueError(\"Oh no!\")\n",
    "except ValueError:\n",
    "  ...\n",
    "\n",
    "\n",
    "model.encode(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name classla/bcms-bertic. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"classla/bcms-bertic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# that's the sentence transformer\n",
    "print(model.max_seq_length)\n",
    "# that's the underlying transformer\n",
    "print(model[0].auto_model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means, the position embedding layer of the transformers has 512 weights, but the sentence transformer will only use and was trained with the first 256 of them. Therefore, you should be careful with increasing the value above 256. It will work from a technical perspective, but the position embedding weights (>256) are not properly trained and can therefore mess up your results. Please also check this StackOverflow post.\n",
    "\n",
    "https://stackoverflow.com/questions/75901231/max-seq-length-for-transformer-sentence-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JINA  \n",
    "https://huggingface.co/jinaai/jina-embeddings-v2-base-en"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
